# The base URL of the OpenAI-compatible API.
# This is the endpoint the agent will send requests to.
# Example for OpenAI: https://api.openai.com/v1
# Example for local Ollama: http://localhost:11434/v1
LLM_BASE_URL=

# The API key for your LLM provider.
# This is also used by the mem0 library for the memory feature.
3# For OpenAI, this is your secret key (e.g., sk-...).
# For a local Ollama instance, the key is simply "ollama".
LLM_API_KEY=

# The specific model name you want the agent to use.
# This must be a model available at the specified base URL.
# Example for OpenAI: gpt-4o-mini
# Example for Ollama: llama3
LLM_CHOICE=
